{"cells":[{"cell_type":"code","execution_count":null,"id":"b9a08689-51a2-4171-bfbf-49db48ad4d34","metadata":{"id":"b9a08689-51a2-4171-bfbf-49db48ad4d34","outputId":"90721cd4-3eeb-4f60-854e-9a26fa273d18"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model_17\"\n","__________________________________________________________________________________________________\n"," Layer (type)                Output Shape                 Param #   Connected to                  \n","==================================================================================================\n"," input_35 (InputLayer)       [(None, 30)]                 0         []                            \n","                                                                                                  \n"," input_36 (InputLayer)       [(None, 30)]                 0         []                            \n","                                                                                                  \n"," embedding_34 (Embedding)    (None, 30, 256)              2102092   ['input_35[0][0]']            \n","                                                          8                                       \n","                                                                                                  \n"," embedding_35 (Embedding)    (None, 30, 256)              2102092   ['input_36[0][0]']            \n","                                                          8                                       \n","                                                                                                  \n"," lstm_34 (LSTM)              [(None, 512),                1574912   ['embedding_34[0][0]']        \n","                              (None, 512),                                                        \n","                              (None, 512)]                                                        \n","                                                                                                  \n"," lstm_35 (LSTM)              [(None, 30, 512),            1574912   ['embedding_35[0][0]',        \n","                              (None, 512),                           'lstm_34[0][1]',             \n","                              (None, 512)]                           'lstm_34[0][2]']             \n","                                                                                                  \n"," dense_17 (Dense)            (None, 30, 82113)            4212396   ['lstm_35[0][0]']             \n","                                                          9                                       \n","                                                                                                  \n","==================================================================================================\n","Total params: 87315649 (333.08 MB)\n","Trainable params: 87315649 (333.08 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","__________________________________________________________________________________________________\n","Input data shape: (13118, 30), (13118, 30)\n","Target data shape: (13118, 30)\n","Epoch 1/10\n","144/164 [=========================>....] - ETA: 50s - loss: 9.3324 - accuracy: 0.2022"]}],"source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, LSTM, Dense, Embedding\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","\n","# Example path to the DailyDialog dataset (replace with your actual path)\n","dailydialog_path = 'C:/Users/Student/Desktop/ViraajM/chatbotProject/dailydialog/ijcnlp_dailydialog/dialogues_text.txt'\n","\n","# Function to load and preprocess data\n","def load_data(file_path, max_samples=50000):\n","    questions = []\n","    answers = []\n","    with open(file_path, 'r', encoding='utf-8') as f:\n","        for line in f:\n","            parts = line.strip().split('__eou__')\n","            if len(parts) > 1:\n","                questions.append(parts[:-1])\n","                answers.append(parts[1:])\n","            if len(questions) >= max_samples:\n","                break\n","    return questions, answers\n","\n","# Load and preprocess the data\n","questions, answers = load_data(dailydialog_path)\n","\n","# Adjust max_seq_length based on your dataset\n","max_seq_length = 30\n","\n","# Tokenization\n","tokenizer = Tokenizer()\n","tokenizer.fit_on_texts(questions)\n","tokenizer.fit_on_texts(answers)\n","\n","# Vocabulary size\n","vocab_size = len(tokenizer.word_index) + 1\n","\n","# Convert text to sequences\n","\n","question_sequences = tokenizer.texts_to_sequences(questions)\n","\n","answer_sequences = tokenizer.texts_to_sequences(answers)\n","\n","# Padding sequences\n","question_sequences = pad_sequences(question_sequences, maxlen=max_seq_length, padding='post')\n","answer_sequences = pad_sequences(answer_sequences, maxlen=max_seq_length+1, padding='post')\n","\n","# Define the model architecture\n","embedding_dim = 256\n","lstm_units = 512\n","\n","# Encoder\n","encoder_inputs = Input(shape=(max_seq_length,))\n","encoder_embedding = Embedding(vocab_size, embedding_dim, mask_zero=True)(encoder_inputs)\n","encoder_lstm = LSTM(lstm_units, return_state=True)\n","_, state_h, state_c = encoder_lstm(encoder_embedding)\n","encoder_states = [state_h, state_c]\n","\n","# Decoder\n","decoder_inputs = Input(shape=(max_seq_length,))\n","decoder_embedding = Embedding(vocab_size, embedding_dim, mask_zero=True)(decoder_inputs)\n","decoder_lstm = LSTM(lstm_units, return_sequences=True, return_state=True)\n","decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n","decoder_dense = Dense(vocab_size, activation='softmax')\n","decoder_outputs = decoder_dense(decoder_outputs)\n","\n","# Define the model\n","model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n","\n","# Compile the model\n","model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","\n","# Print model summary\n","model.summary()\n","\n","# Define input and target data for training\n","input_data = [question_sequences, answer_sequences[:, :-1]]\n","target_data = answer_sequences[:, 1:]\n","\n","# Print shapes for debugging\n","print(f\"Input data shape: {input_data[0].shape}, {input_data[1].shape}\")\n","print(f\"Target data shape: {target_data.shape}\")\n","\n","# Train the model\n","model.fit(input_data, target_data, batch_size=64, epochs=10, validation_split=0.2)\n","\n","# Example usage of generating response (assuming the model is trained)\n","def generate_response(input_text):\n","    input_seq = tokenizer.texts_to_sequences([input_text])\n","    input_seq = pad_sequences(input_seq, maxlen=max_seq_length, padding='post')\n","\n","    # Encode the input sequence\n","    states_value = encoder_model.predict(input_seq)\n","\n","    # Generate empty target sequence of length 1\n","    target_seq = np.zeros((1, 1))\n","    target_seq[0, 0] = tokenizer.word_index['<start>']  # Start token\n","\n","    stop_condition = False\n","    generated_response = ''\n","    while not stop_condition:\n","        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n","\n","        # Sample a token\n","        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n","        sampled_token = tokenizer.index_word[sampled_token_index]\n","\n","        if sampled_token != '<end>':\n","            generated_response += sampled_token + ' '\n","\n","        # Exit condition: either hit max length or find stop token\n","        if sampled_token == '<end>' or len(generated_response.split()) > max_seq_length:\n","            stop_condition = True\n","\n","        # Update the target sequence\n","        target_seq = np.zeros((1, 1))\n","        target_seq[0, 0] = sampled_token_index\n","\n","        # Update states\n","        states_value = [h, c]\n","\n","    return generated_response\n","\n","# Example usage\n","input_text = \"Can you help me with my computer?\"\n","response = generate_response(input_text)\n","print(f\"Bot: {response}\")\n"]},{"cell_type":"code","execution_count":null,"id":"6dac3de0-68ef-4354-a365-4cf22660ac96","metadata":{"id":"6dac3de0-68ef-4354-a365-4cf22660ac96"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.0"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}